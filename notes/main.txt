# 이 파일이 모든 인프라를 연결합니다.

provider "aws" {
  region = var.aws_region
}
# SSH 키 생성
resource "tls_private_key" "deployer" {
  algorithm = "RSA"
  rsa_bits  = 4096
}

# AWS에 공개키 등록
resource "aws_key_pair" "deployer" {
  key_name   = "k3s-deployer"
  public_key = tls_private_key.deployer.public_key_openssh
}

# 보안 그룹: 80번(HTTP)과 22번(SSH) 문을 엽니다.
resource "aws_security_group" "web_sg" {
  name = "web_server_sg"
  vpc_id = aws_vpc.main.id
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"] # 실제로는 본인 IP만 허용하는 게 좋습니다.
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
# 모니터링 서버 전용 보안 그룹 
resource "aws_security_group" "monitoring_sg" {
  name = "monitoring_server_sg"
  vpc_id = aws_vpc.main.id
  ingress {
    from_port   = 9090 # 프로메테우스 기본 포트
    to_port     = 9090
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 22 # SSH 접속용            
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"] 
  }
}
# 1. VPC 생성
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
  tags = { Name = "Main-VPC" }
}

# 2. 서브넷 생성 (고가용성을 위해 2개의 가용영역 사용)
resource "aws_subnet" "public_1" {
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.1.0/24"
  availability_zone = "ap-northeast-2a"
  tags = { Name = "Public-Subnet-1" }
}
# public_1 밑에 추가하세요
resource "aws_subnet" "public_2" {
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.3.0/24"
  availability_zone = "ap-northeast-2b" # 2a가 아닌 다른 구역
  tags = { Name = "Public-Subnet-2" }
}
resource "aws_subnet" "private_1" {
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.2.0/24"
  availability_zone = "ap-northeast-2a"
  tags = { Name = "Private-Subnet-1" }
}
# 2번 프라이빗 서브넷 추가 (장애 대응용)
resource "aws_subnet" "private_2" {
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.4.0/24"
  availability_zone = "ap-northeast-2b" # 2c가 아닌 다른 구역
  tags = { Name = "Private-Subnet-2" }
}
# 3. 인터넷 관문 (Public용)
resource "aws_internet_gateway" "igw" {
  vpc_id = aws_vpc.main.id
}

resource "aws_route_table" "public_rt" {
  vpc_id = aws_vpc.main.id
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.igw.id
  }
}

resource "aws_route_table_association" "public_assoc" {
  subnet_id      = aws_subnet.public_1.id
  route_table_id = aws_route_table.public_rt.id
}
# 2번 프라이빗 서브넷도 NAT를 쓰도록 연결
resource "aws_route_table_association" "private_assoc_2" {
  subnet_id      = aws_subnet.private_2.id
  route_table_id = aws_route_table.private_rt.id
}

# 1. NAT가 사용할 고정 IP(EIP) 하나 예약
resource "aws_eip" "nat_eip" {
  domain = "vpc"
}

# 2. NAT 게이트웨이 생성 (반드시 퍼블릭 서브넷에 두어야 함)
resource "aws_nat_gateway" "nat_gw" {
  allocation_id = aws_eip.nat_eip.id
  subnet_id     = aws_subnet.public_1.id # 입구는 퍼블릭에!
  tags          = { Name = "Main-NAT" }
}

# 3. 프라이빗 전용 라우팅 테이블 (프라이빗 서버들을 위한 지도)
resource "aws_route_table" "private_rt" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block     = "0.0.0.0/0"
    nat_gateway_id = aws_nat_gateway.nat_gw.id # 인터넷 나갈 거면 NAT로 가라!
  }
}

# 4. 프라이빗 서브넷에 이 지도를 쥐어주기
resource "aws_route_table_association" "private_assoc" {
  subnet_id      = aws_subnet.private_1.id
  route_table_id = aws_route_table.private_rt.id
}
# EC2 설정에 보안 그룹 연결
# 통합된 EC2 생성 코드
resource "aws_instance" "web_server" {
  count                  = 2
  ami                    = "ami-040c33c6a51fd5d96" 
  instance_type          = "t2.micro"
  vpc_security_group_ids = [aws_security_group.web_sg.id]
  subnet_id = element([aws_subnet.private_1.id, aws_subnet.private_2.id], count.index)
  tags = { 
    Name = "My-Web-Server-${count.index}" 
  }
}
resource "aws_instance" "monitoring_server" {
  ami                    = "ami-040c33c6a51fd5d96" # 동일한 Ubuntu 이미지 사용 [cite: 2, 5]
  instance_type          = "t2.micro"             # 프로메테우스는 메모리를 많이 쓰므로 t2.medium 추천
  vpc_security_group_ids = [aws_security_group.monitoring_sg.id]
  subnet_id            = aws_subnet.public_1.id 
  iam_instance_profile = aws_iam_instance_profile.monitoring_profile.name 
  tags = {
    Name = "Monitoring-Server-Prometheus" # 모니터링 전용 태그 [cite: 3]
  }
}
# 1. 로드밸런서 본체
resource "aws_lb" "web_alb" {
  name               = "web-app-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.web_sg.id]
  subnets = [aws_subnet.public_1.id, aws_subnet.public_2.id] # ALB는 서브넷 2개 이상 필요
}

# 2. 대상 그룹 (앱 서버들을 담는 바구니)
resource "aws_lb_target_group" "app_tg" {
  name     = "app-target-group"
  port     = 80
  protocol = "HTTP"
  vpc_id   = aws_vpc.main.id
}

# 3. 리스너 (80포트로 오면 대상 그룹으로 전달)
resource "aws_lb_listener" "http" {
  load_balancer_arn = aws_lb.web_alb.arn
  port              = "80"
  protocol          = "HTTP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.app_tg.arn
  }
}

# 4. 앱 서버들을 로드밸런서에 연결
resource "aws_lb_target_group_attachment" "app_attach" {
  count            = 2
  target_group_arn = aws_lb_target_group.app_tg.arn
  target_id        = aws_instance.web_server[count.index].id
  port             = 80
}

# 1. 모니터링 서버용 역할
resource "aws_iam_role" "monitoring_role" {
  name = "monitoring_server_role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = { Service = "ec2.amazonaws.com" }
    }]
  })
}

# 2. EC2 정보를 읽을 수 있는 권한 부여 (Read Only)
resource "aws_iam_role_policy_attachment" "ec2_read" {
  role       = aws_iam_role.monitoring_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ReadOnlyAccess"
}

# 3. EC2에 이 신분증을 부착할 '프로필' 생성
resource "aws_iam_instance_profile" "monitoring_profile" {
  name = "monitoring_instance_profile"
  role = aws_iam_role.monitoring_role.name
}

# 4. 기존 monitoring_server 리소스에 아래 한 줄 추가!
# iam_instance_profile = aws_iam_instance_profile.monitoring_profile.name
# 1. 파이썬 코드를 람다용 zip 파일로 압축 (자동화)
data "archive_file" "start_zip" {
  type        = "zip"
  source_file = "${path.module}/ec2_start.py"
  output_path = "${path.module}/ec2_start.zip"
}

data "archive_file" "stop_zip" {
  type        = "zip"
  source_file = "${path.module}/ec2_stop.py"
  output_path = "${path.module}/ec2_stop.zip"
}

# 2. 람다용 IAM 역할(Role) 생성
resource "aws_iam_role" "lambda_role" {
  name = "ec2_scheduler_lambda_role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = { Service = "lambda.amazonaws.com" }
    }]
  })
}

# 3. EC2 제어 권한(Policy) 정의 및 연결
resource "aws_iam_role_policy" "ec2_policy" {
  name = "ec2_control_policy"
  role = aws_iam_role.lambda_role.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect   = "Allow"
        Action   = ["ec2:StartInstances", "ec2:StopInstances", "ec2:DescribeInstances"]
        Resource = "*"
      },
      {
        Effect   = "Allow"
        Action   = ["logs:CreateLogGroup", "logs:CreateLogStream", "logs:PutLogEvents"]
        Resource = "arn:aws:logs:*:*:*"
      }
    ]
  })
}

# 4. 람다 함수 정의 (시작용)

# 이 블럭은 environment 블럭을 통해 전원을 켤 인스턴스 이름이 담긴 리스트를
# INSTANCE_IDS라는 이름으로 전달 받고 filename을 통해 
# handler에서 실행할 코드가 담긴 압축 파일을 접근을 하고 
# handler를 통해 압축파일의 코드(인스턴스 시작)를 실행

resource "aws_lambda_function" "ec2_start_lambda" {
  filename         = data.archive_file.start_zip.output_path
  function_name    = "EC2_Start_Function"
  role             = aws_iam_role.lambda_role.arn
  handler          = "ec2_start.lambda_handler"
  runtime          = "python3.9"

# aws_lambda_function 리소스의 문서를 보면 role 항목에 **"IAM Role의 ARN을 넣어야 한다"**라고 정의되어 있습니다.
  environment {
    variables = {
      # [중요!] 생성된 EC2 2대의 ID를 쉼표로 합쳐서 자동으로 전달합니다.
      INSTANCE_IDS = join(",", aws_instance.web_server[*].id)
    }
  }
}
# data.archive_file.stop_zip : 
# 람다 함수의 소스 코드가 담긴 압축 파일에 대한 모든 정보
# output_path : 
# 그 압축 파일의 경로를 의미
# ${path.module}/ec2_stop.zip 와 같은 의미

# 호출 (Trigger): 어떤 이벤트(예: 스케줄러)가 람다를 깨웁니다.

# 권한 획득 (Role): aws_iam_role.lambda_role.arn에 정의된 신분증을 가슴에 딱 붙입니다. 이 신분증 덕분에 EC2를 켜거나 끌 수 있는 **'권한'**이 생깁니다.

# 파일 탐색 (Handler - 앞부분): handler의 "ec2_start" 부분을 보고, 압축 파일(ZIP) 안에 있는 ec2_start.py라는 파일을 찾습니다.

# 함수 실행 (Handler - 뒷부분): 파일 안에서 "lambda_handler"라고 이름 붙여진 함수를 찾아 실행합니다. 이때 INSTANCE_IDS 같은 환경 변수를 들고 들어갑니다.

# 5. 람다 함수 정의 (중지용)
resource "aws_lambda_function" "ec2_stop_lambda" {
  filename         = data.archive_file.stop_zip.output_path
  function_name    = "EC2_Stop_Function"
  role             = aws_iam_role.lambda_role.arn
  handler          = "ec2_stop.lambda_handler"
  runtime          = "python3.9"
  source_code_hash = data.archive_file.stop_zip.output_base64sha256
 # 람다 함수가 변경되었는지 확인하는 용도
 # .output_base64sha256: 압축된 결과물의 지문(해시값)을 가져오라는 뜻
 #이 줄이 없으면, 여러분이 파이썬 코드를 수정하고 아무리 apply를 해도 
 # AWS에 있는 람다 코드는 옛날 버전 그대로 멈춰있을 확률이 높습니다. 
 # 즉, **"코드 수정 사항을 강제로 반영시키기 위한 필수 장치"**라고 보시면 됩니다.
  environment {
    variables = {
      INSTANCE_IDS = join(",", aws_instance.web_server[*].id)
    }
  }
}

# 6. EventBridge (스케줄러) - 10시 시작
# 알람 시계 만들기: aws_cloudwatch_event_rule (지금 하신 것)

# 시계와 람다 연결: "시계가 울리면 이 람다를 실행해!" (aws_cloudwatch_event_target)

# 람다의 허락: "알람 시계가 나를 깨우는 것을 허락할게!" (aws_lambda_permission)
resource "aws_cloudwatch_event_rule" "start_rule" {
  name                = "ec2_start_rule"
  schedule_expression = "cron(0 1 * * ? *)" # UTC 01:00 = KST 10:00
}

resource "aws_cloudwatch_event_target" "start_target" {
  rule      = aws_cloudwatch_event_rule.start_rule.name
  target_id = "start_lambda"
  arn       = aws_lambda_function.ec2_start_lambda.arn
}
# target_id : 
# EventBridge 내에서 타겟을 식별하는 고유 ID입니다.
# 알람을 들려줄 대상과 연결된 다리의 이름
# 7. EventBridge (스케줄러) - 14시 중지
resource "aws_cloudwatch_event_rule" "stop_rule" {
  name                = "ec2_stop_rule"
  schedule_expression = "cron(0 5 * * ? *)" # UTC 05:00 = KST 14:00
}

resource "aws_cloudwatch_event_target" "stop_target" {
  rule      = aws_cloudwatch_event_rule.stop_rule.name
  target_id = "stop_lambda"
  arn       = aws_lambda_function.ec2_stop_lambda.arn
}

# 8. EventBridge가 람다를 호출할 수 있게 권한 부여
resource "aws_lambda_permission" "allow_start" {
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.ec2_start_lambda.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.start_rule.arn
}

resource "aws_lambda_permission" "allow_stop" {
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.ec2_stop_lambda.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.stop_rule.arn
}
# aws_lambda_permission
# 람다 함수에 특정 주체(여기서는 EventBridge)가 접근할 수 있는 권한을 부여합니다.
# 알람을 들려줄 대상(람다 함수)에게 이벤트 브릿지로 연결을 했는데 
# 그마저도 허락이 필요함
#보안상의 이유: 누군가 내 계정의 다른 알람 시계(Rule)를 마음대로 만들어서, 내가 애지중지 만든 람다 함수를 미친 듯이 호출(Invoke)해버리면 비용이 폭탄처럼 나올 수 있겠죠?
#검문소 역할: 그래서 람다는 **"오직 내가 허락한 특정 알람 시계(source_arn)만이 나를 깨울 수 있다!"**라고 문 앞에 써 붙여 놓는 것입니다.
/*
1. action = "lambda:InvokeFunction"
의미: "어떤 행동을 허락할 것인가?"
상세: 람다의 가장 핵심적인 기능인 **'실행(Invoke)'**을 허락한다는 뜻입니다. 이 권한이 있어야만 외부에서 람다의 스위치를 누를 수 있습니다.

2. function_name = aws_lambda_function.ec2_start_lambda.function_name
의미: "누구의 대문을 열어줄 것인가?"
상세: 허락을 해줄 주인공(대상)을 지정합니다. 여기서는 우리가 아까 만든 ec2_start_lambda라는 람다 함수가 그 주인공입니다.

3. principal = "events.amazonaws.com"
의미: "어떤 종류의 손님인가? (신분 확인)"
상세: 이 손님은 **'EventBridge(CloudWatch Events)'**라는 서비스에서 온 손님이라는 뜻입니다. AWS의 각 서비스는 고유한 이름(Service Principal)을 가지고 있는데, 알람 시계 서비스의 이름이 바로 events.amazonaws.com입니다.

4. source_arn = aws_cloudwatch_event_rule.start_rule.arn
의미: "딱 이 알람 시계가 맞나? (주소 확인)"
상세: 가장 중요한 보안 필터입니다. 그냥 '알람 서비스'면 다 통과시키는 게 아니라, **"오직 우리가 만든 start_rule이라는 특정 알람 시계"**에서 온 신호만 받겠다는 뜻입니다.
*/


# ** 
# ARN (주소)이 필요한 경우: * 서로 다른 서비스끼리 통신할 때 주로 씁니다. (예: EventBridge가 Lambda를 호출할 때)
# AWS 전체 시스템에서 "이 녀석은 확실히 이 계정의 이 지역에 있는 녀석이다"라는 완전한 식별이 필요할 때 사용합니다.
# 다른 서비스 간에 권한을 주거나 호출할 때 (예: IAM, Lambda)

# Name (이름)이 필요한 경우:
# 같은 서비스 안에서 리소스를 묶어줄 때 주로 씁니다. (예: CloudWatch Rule에 CloudWatch Target을 붙일 때)
# 같은 서비스 내에서 이름을 부를 때 (예: CloudWatch Rule 이름)

# ID (아이디)가 필요한 경우:
# 리소스를 조작하거나 특정 번호로 식별해야 할 때 (예: EC2 ID, VPC ID, Subnet ID)
# 리소스를 조작하거나 참조할 때 (예: 보안 그룹 ID, 서브넷 ID)
# **Primary Key(기본키)**와 같습니다. 이름(name)은 중복될 수도 있고, ARN은 너무 길어서 다루기 불편할 때가 있죠. 
# 하지만 .id는 클라우드 제공자(AWS/KT Cloud)가 해당 리소스를 제어하기 위해 만든 최적화된 코드

# 10. Ansible 인벤토리 파일 자동 생성
resource "local_file" "ansible_inventory" {
  content = <<-EOT
[master]
# 앱 서버는 프라이빗 서브넷에 있으므로 private_ip를 써야 합니다.
${aws_instance.web_server[0].private_ip} ansible_user=ubuntu ansible_ssh_private_key_file=../k3s-deployer.pem

[worker]
${aws_instance.web_server[1].private_ip} ansible_user=ubuntu ansible_ssh_private_key_file=../k3s-deployer.pem

[monitoring]
# 모니터링 서버는 외부에서 접속해야 하므로 public_ip를 씁니다.
${aws_instance.monitoring_server.public_ip} ansible_user=ubuntu ansible_ssh_private_key_file=../k3s-deployer.pem

[k3s_cluster:children]
master
worker

[k3s_cluster:vars]
ansible_user=ubuntu
ansible_ssh_private_key_file=../k3s-deployer.pem
# ★핵심: 모니터링 서버를 경유(ProxyJump)해서 프라이빗 서버로 접속하는 설정
ansible_ssh_common_args='-o StrictHostKeyChecking=no -o ProxyCommand="ssh -W %h:%p -q ubuntu@${aws_instance.monitoring_server.public_ip} -i ../k3s-deployer.pem"'
EOT

  filename = "${path.module}/ansible/inventory/aws.ini"
  depends_on = [aws_instance.web_server, aws_instance.monitoring_server, local_file.ssh_key]
}